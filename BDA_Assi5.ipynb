{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO986Ha758WN7pN2lRjOv/2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishesh711/BDA_HW5/blob/main/BDA_Assi5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper.py"
      ],
      "metadata": {
        "id": "opZ8hetCZUtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ewba6yn0dJum",
        "outputId": "bb91c7e9-a625-4450-ccd5-bc2bb5d73c26"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as scio\n",
        "\n",
        "def load_data(dataloc):\n",
        "\tdata = scio.loadmat(dataloc)\n",
        "\treturn data['A']"
      ],
      "metadata": {
        "id": "c89OFE3BZUY4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution.py"
      ],
      "metadata": {
        "id": "tXcNFvi_Za70"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9A_NU9xaTTfE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pickle, tqdm, os, time\n",
        "'''\n",
        "Assignment5: Autoencoders\n",
        "\n",
        "Useful numpy functions\n",
        "----------------------\n",
        "In this assignment, you may want to use following helper functions:\n",
        "- np.linalg.svd(): compute the singular value decomposition on a given matrix.\n",
        "- np.dot(): matrices multiplication operation.\n",
        "- np.mean(): compute the mean value on a given matrix.\n",
        "- np.zeros(): generate a all '0' matrix with a certain shape.\n",
        "- np.expand_dims: expand the dimension of an array at the referred axis.\n",
        "- np.squeeze: Remove single-dimensional entries from the shape of an array.\n",
        "- np.transpose(): matrix transpose operation.\n",
        "- np.linalg.norm(): compute the norm value of a matrix. You may use it for the reconstruct_error function.\n",
        "\n",
        "Pytorch functions and APIs you may need\n",
        "------------------------------------------\n",
        "torch.empty\n",
        "torch.mm\n",
        "torch.transpose\n",
        "nn.Parameter\n",
        "nn.init.kaiming_normal_\n",
        "nn.Tanh\n",
        "nn.ReLU\n",
        "nn.Sigmoid\n",
        "'''\n",
        "\n",
        "def frobeniu_norm_error(A, B):\n",
        "    '''\n",
        "    To compute Frobenius norm's square of the matrix A-B. It can serve as the\n",
        "    reconstruction error between A and B, or can be used to compute the\n",
        "    difference between A and B.\n",
        "\n",
        "    Args:\n",
        "    A & B: Two matrices needed to be compared with. Should be of same shape.\n",
        "\n",
        "    Return:\n",
        "    error: the Frobenius norm's square of the matrix A-B. A scaler number.\n",
        "    '''\n",
        "    return np.linalg.norm(A-B)\n",
        "\n",
        "\n",
        "\n",
        "class AE(nn.Module):\n",
        "    '''\n",
        "    Important!! Read before starting.\n",
        "    1. To coordinate with the note at http://people.tamu.edu/~sji/classes/PCA.pdf and\n",
        "    compare with PCA, we set the shape of input to the network as [256, n_samples].\n",
        "    2. Do not do centering. Even though X in the note is the centered data, the neural network is\n",
        "    capable to learn this centering process. So unlike PCA, we don't center X for autoencoders,\n",
        "    and we will still get the same results.\n",
        "    3. Don't change or slightly change hyperparameters like learning rate, batch size, number of\n",
        "    epochs for 5(c) and 5(d). But for 5(e), you can try more hyperparameters and achieve as good results\n",
        "    as you can.\n",
        "\n",
        "    '''\n",
        "    def __init__(self, d_hidden_rep):\n",
        "        '''\n",
        "        Args:\n",
        "            d_hidden_rep: The dimension for the hidden representation in AE. A scaler number.\n",
        "            n_features: The number of initial features, 256 for this dataset.\n",
        "\n",
        "        Attributes:\n",
        "            X: A torch tensor of shape [256, None]. A placeholder\n",
        "               for input images. \"None\" refers to any batch size.\n",
        "            out_layer: A torch tensor of shape [256, None]. Output signal\n",
        "               of network\n",
        "            initializer: Initialize the trainable weights.\n",
        "        '''\n",
        "        super(AE, self).__init__()\n",
        "        self.d_hidden_rep = d_hidden_rep\n",
        "        self.n_features = 256\n",
        "        self._network()\n",
        "\n",
        "    def _network(self):\n",
        "        '''\n",
        "\n",
        "        You are free to use the listed functions and APIs from torch or torch.nn:\n",
        "            torch.empty\n",
        "            nn.Parameter\n",
        "            nn.init.kaiming_normal_\n",
        "\n",
        "        You need to define and initialize weights here.\n",
        "\n",
        "        '''\n",
        "\n",
        "        ### YOUR CODE HERE\n",
        "\n",
        "        '''\n",
        "        Note: you should include all the three variants of the networks here.\n",
        "        You can comment the other two when you running one, but please include\n",
        "        and uncomment all the three in you final submissions.\n",
        "        '''\n",
        "\n",
        "        # Note: here for the network with weights sharing. Basically you need to follow the\n",
        "\n",
        "\n",
        "        # Note: here for the network without weights sharing\n",
        "\n",
        "\n",
        "        # Note: here for the network with more layers and nonlinear functions\n",
        "\n",
        "\n",
        "\n",
        "        ### END YOUR CODE\n",
        "\n",
        "    def _forward(self, X):\n",
        "        '''\n",
        "\n",
        "        You are free to use the listed functions and APIs from torch and torch.nn:\n",
        "            torch.mm\n",
        "            torch.transpose\n",
        "            nn.Tanh\n",
        "            nn.ReLU\n",
        "            nn.Sigmoid\n",
        "\n",
        "        Args:\n",
        "            X: A torch tensor of shape [n_features, batch_size].\n",
        "                for input images.\n",
        "\n",
        "        Returns:\n",
        "            out: A torch tensor of shape [n_features, batch_size].\n",
        "\n",
        "        '''\n",
        "\n",
        "        ### YOUR CODE HERE\n",
        "\n",
        "        '''\n",
        "        Note: you should include all the three variants of the networks here.\n",
        "        You can comment the other two when you running one, but please include\n",
        "        and uncomment all the three in you final submissions.\n",
        "        '''\n",
        "\n",
        "        # Note: here for the network with weights sharing. Basically you need to follow the\n",
        "        # formula (WW^TX) in the note at http://people.tamu.edu/~sji/classes/PCA.pdf .\n",
        "\n",
        "\n",
        "        # Note: here for the network without weights sharing\n",
        "\n",
        "\n",
        "        # Note: here for the network with more layers and nonlinear functions\n",
        "\n",
        "\n",
        "        ### END YOUR CODE\n",
        "\n",
        "    def _setup(self):\n",
        "        '''\n",
        "        Model and training setup.\n",
        "\n",
        "        Attributes:\n",
        "            loss: MSE loss function for computing on the current batch.\n",
        "            optimizer: torch.optim. The optimizer for training\n",
        "                the model. Different optimizers use different gradient\n",
        "                descend policies.\n",
        "        '''\n",
        "        self.loss = nn.MSELoss(reduction='mean')\n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "    def train(self, x_train, x_valid, batch_size, max_epoch):\n",
        "\n",
        "        '''\n",
        "        Autoencoder is an unsupervised learning method. To compare with PCA,\n",
        "        it's ok to use the whole training data for validation and reconstruction.\n",
        "        '''\n",
        "\n",
        "        self._setup()\n",
        "\n",
        "        num_samples = x_train.shape[1]\n",
        "        num_batches = int(num_samples / batch_size)\n",
        "\n",
        "        num_valid_samples = x_valid.shape[1]\n",
        "        num_valid_batches = (num_valid_samples - 1) // batch_size + 1\n",
        "\n",
        "        print('---Run...')\n",
        "        for epoch in range(1, max_epoch + 1):\n",
        "\n",
        "            # To shuffle the data at the beginning of each epoch.\n",
        "            shuffle_index = np.random.permutation(num_samples)\n",
        "            curr_x_train = x_train[:, shuffle_index]\n",
        "\n",
        "            # To start training at current epoch.\n",
        "            loss_value = []\n",
        "            qbar = tqdm.tqdm(range(num_batches))\n",
        "            for i in qbar:\n",
        "                batch_start_time = time.time()\n",
        "\n",
        "                start = batch_size * i\n",
        "                end = batch_size * (i + 1)\n",
        "                x_batch = curr_x_train[:, start:end]\n",
        "\n",
        "                x_batch_tensor = torch.tensor(x_batch).float()\n",
        "                x_batch_re_tensor = self._forward(x_batch_tensor)\n",
        "                loss = self.loss(x_batch_re_tensor, x_batch_tensor)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                if not i % 10:\n",
        "                    qbar.set_description(\n",
        "                        'Epoch {:d} Loss {:.6f}'.format(\n",
        "                            epoch, loss.detach().item()))\n",
        "\n",
        "            # To start validation at the end of each epoch.\n",
        "            loss = 0\n",
        "            print('Doing validation...', end=' ')\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for i in range(num_valid_batches):\n",
        "                    start = batch_size * i\n",
        "                    end = min(batch_size * (i + 1), x_valid.shape[1])\n",
        "                    x_valid_batch = x_valid[:, start:end]\n",
        "\n",
        "                    x_batch_tensor = torch.tensor(x_valid_batch).float()\n",
        "                    x_batch_re_tensor = self._forward(x_batch_tensor)\n",
        "                    loss = self.loss(x_batch_re_tensor, x_batch_tensor)\n",
        "\n",
        "            print('Validation Loss {:.6f}'.format(loss.detach().item()))\n",
        "\n",
        "\n",
        "    def get_params(self):\n",
        "        \"\"\"\n",
        "        Get parameters for the trained model.\n",
        "\n",
        "        Returns:\n",
        "            final_w: A numpy array of shape [n_features, d_hidden_rep].\n",
        "        \"\"\"\n",
        "        return self.w.detach().numpy()\n",
        "\n",
        "    def reconstruction(self, X):\n",
        "        '''\n",
        "        To reconstruct data. Youâ€™re required to reconstruct one by one here,\n",
        "        that is to say, for one loop, input to the network is of the shape [n_features, 1].\n",
        "        Args:\n",
        "            X: The data matrix with shape [n_features, n_any], a numpy array.\n",
        "        Returns:\n",
        "            X_re: The reconstructed data matrix, which has the same shape as X, a numpy array.\n",
        "        '''\n",
        "        _, n_samples = X.shape\n",
        "        with torch.no_grad():\n",
        "            for i in range(n_samples):\n",
        "                ### YOUR CODE HERE\n",
        "\n",
        "                # Note: Format input curr_X to the shape [n_features, 1]\n",
        "\n",
        "                ### END YOUR CODE\n",
        "                curr_X_tensor = torch.tensor(curr_X).float()\n",
        "                curr_X_re_tensor = self._forward(curr_X_tensor)\n",
        "                ### YOUR CODE HERE\n",
        "\n",
        "                # Note: To achieve final reconstructed data matrix with the shape [n_features, n_any].\n",
        "\n",
        "            ### END YOUR CODE\n",
        "        return X_re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main.py"
      ],
      "metadata": {
        "id": "VkoF1EzmZet1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from helper import load_data\n",
        "from solution import AE, frobeniu_norm_error\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "def test_ae(A, p):\n",
        "    model = AE(d_hidden_rep=p)\n",
        "    model.train(A, A, 128, 300)\n",
        "    A_re = model.reconstruction(A)\n",
        "    final_w = model.get_params()\n",
        "    error = frobeniu_norm_error(A, A_re)\n",
        "    print('AE-Reconstruction error for {k}-dimensional hidden representation is'.format(k=p), error)\n",
        "    return final_w\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    dataloc = \"/content/USPS.mat\"\n",
        "    A = load_data(dataloc)\n",
        "    A = A.T\n",
        "    ## Normalize A\n",
        "    A = A/A.max()\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "    # Note: You are free to modify your code here for debugging and justifying your ideas\n",
        "    ps = [10, 50, 100, 200]\n",
        "    for p in ps:\n",
        "        final_w = test_ae(A, p)\n",
        "    ### END YOUR CODE\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "HYM4ixN2ZcxC",
        "outputId": "779ad650-b515-4568-d9e2-4250c716e82a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "optimizer got an empty parameter list",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-bf7cb84c22b2>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mfinal_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;31m### END YOUR CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-bf7cb84c22b2>\u001b[0m in \u001b[0;36mtest_ae\u001b[0;34m(A, p)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_ae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_hidden_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mA_re\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfinal_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/solution.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, x_valid, batch_size, max_epoch)\u001b[0m\n\u001b[1;32m    169\u001b[0m         '''\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/solution.py\u001b[0m in \u001b[0;36m_setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m         '''\n\u001b[1;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         )\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizer got an empty parameter list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_nGtHwI2Zioa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}